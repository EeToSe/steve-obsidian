---
categories: "[[Clippings]]"
topics:
author:
  - "[[Axios]]"
source: "https://www.youtube.com/watch?v=tDSDR7QILLg"
published: 2025-12-05
created: 2025-12-08
tags:
  - "clippings"
  - "todo"
status:
---
![](https://www.youtube.com/watch?v=tDSDR7QILLg)  

### **As a Scientist and Researcher:**

- **Scientific Method as a Core Principle:** Hassabis emphasizes that the scientific method is his default approach to everything, including business (4:00-4:33). He believes it's the most important idea humanity has ever had, leading to the enlightenment and modern civilization, and that its rigor and precision provide an edge in research and engineering (4:57-5:01).
- **Pragmatism over Dogma:** He highlights that a true scientist cannot be too dogmatic about an idea; instead, they must follow where empirical evidence leads them (19:59-20:09). This pragmatic approach guided DeepMind's pivot to focus on large language models (LLMs) when their scaling capabilities became evident (21:09-21:16).
- **Continuous Innovation and Exploration:** Hassabis admits that even as a creator, he often hasn't explored a tenth of what the existing AI systems can do because the pace of innovation is so fast, and they are constantly focused on the next breakthrough (18:41-19:01). Users often push the models further than they initially did internally (19:07-19:10).

### **As an Engineer:**

- **Blending World-Class Capabilities:** He stresses the necessity of blending world-class research, engineering, and infrastructure to be at the frontier of AI (5:06-5:15).
- **Focus on Usefulness and Impact:** Hassabis aims for Gemini to become a "universal assistant" that is useful in everyday life, improving productivity and personal life, with the goal of creating something people consult many times a day (7:35-8:10).
- **Anticipating Commercial Needs:** He believes that capitalism will naturally reward responsible AI actors because businesses will demand guarantees about an agent's behavior and data handling, driving safer development (11:45-12:14).

### **As a Gamer:**

- **Decision-Making and Planning Training:** Hassabis credits his chess background and other games as critical to his work in both business and science (26:16-26:22). He sees games as microcosms of the real world, providing an invaluable way to practice and train decision-making and planning capabilities by allowing multiple "practice goes" at critical moments (26:38-27:09).
- **Creativity in Development:** He loves the creativity involved in making games (26:27-26:29).

### **Overall Personal Takeaways:**

- **Leveraging Platforms for Important Discussions:** The Nobel Prize, for example, gives him a platform to speak out about important issues like AI safety and the responsible use of AI, as well as preparing society for the arrival of AGI (2:13-2:27, 2:44-3:27).
- **Optimism for Human Adaptability:** Despite the massive and rapid disruption AI will bring, Hassabis is a "really big believer in human ingenuity" and that humans are "infinitely adaptable." He points to the human brain's adaptation from hunter-gatherer times to modern civilization as proof of our general intelligence and ability to keep up (27:32-28:12).
- **Mission-Driven Talent:** He believes the best scientists, researchers, and engineers are attracted to work on the most cutting-edge problems and have the most positive impact on the world, which is what Google DeepMind aims to offer (24:57-25:21).

## Predictions and insights about the AI future

- **Next 12 Months of Progress (5:50-7:10):**
    
    - He predicts a strong emphasis on the **convergence of modalities**, meaning AI systems like Gemini will increasingly process and produce images, video, text, and audio. He notes that DeepMind's Gemini is multimodal from the beginning, leading to "cross-pollination" and "astonishing understanding of visuals" (6:06-6:39).
    - Expect to see "very interesting combinations of capabilities" when video converges with language models (6:46-6:51).
    - He is personally working on **world models**, like their system Genie 3, which is an interactive video model allowing users to generate video and then "walk around it like you're in a game or simulation," maintaining coherence for a minute (6:54-7:09).
- **Progress of Agent-Based Systems (7:14-8:27):**
    
    - Hassabis states that while agents are currently "not reliable enough to do full tasks," over the next year, he expects them to be "close" to being able to complete entire tasks reliably (7:17-7:22, 8:25-8:29).
    - DeepMind envisions a "universal assistant" (Gemini) that will be on more devices, including glasses, to become a part of the fabric of daily life, improving productivity and offering personal recommendations (7:35-8:10).
- **Timeline for AGI (21:39-21:45):**
    
    - He predicts that **Artificial General Intelligence (AGI)**—defined as a system exhibiting all human cognitive, inventive, and creative capabilities—is **five to ten years away** (21:41-21:45).
    - He notes that current LLMs are "jagged intelligences" with flaws despite impressive "PhD levels" skills in some areas, lacking "across the board consistency" and capabilities like continual learning, online learning, and long-term planning and reasoning (22:04-22:27).
- **Path to AGI (23:05-23:48):**
    
    - He believes that **scaling current AI systems to their maximum** is crucial, as it will be at least a "key component" of the final AGI system, and there's a chance scaling alone could get there (23:10-23:24).
    - However, his "best guess" is that **one or two more "big breakthroughs"**—on the level of the Transformer or AlphaGo—will be required in addition to scaling (23:24-23:48).
- **Best and Worst Case Scenarios for AI (8:40-10:10):**
    
    - **Best Case (Radical Abundance):** He dreams of a future where AI helps solve humanity's biggest issues like clean energy and diseases, leading to a "post-scarcity era" where humanity flourishes and potentially spreads consciousness to the galaxy (8:43-9:30).
    - **Worst Case (Fears):** His primary fears are:
        - **Bad actors using AI for harmful ends** (9:57-10:01).
        - **AI itself "going off the rails"** as it becomes more agentic and harms humanity (10:01-10:09).
- **Specific Catastrophic Outcomes (10:20-11:00):**
    
    - **Pathogens created by evil actors using AI:** He considers this "definitely one of the one of the bad use case scenarios that we have to guard against for sure" (10:26-10:30).
    - **Energy or water cyber terror using AI by a foreign actor:** He believes this is "probably almost already happening now" and is the "most obvious vulnerable vector" (10:36-10:45). DeepMind is focusing on "AI for cyber security" to power up defenses (10:47-10:56).
    - **AI operating outside human control on its own:** He notes that as agentic and autonomous systems become more sophisticated, there's more room for them to "deviate from what you maybe had intended" (11:01-11:24). He acknowledges that the potential for AI to "jump the moat, jump the guard rail" is "non zero," but he dismisses precise percentages as "nonsense" (12:29-13:06).
- **US vs. China in AI (13:13-14:08):**
    
    - He believes the **US and the West are still in the lead** in AI, looking at benchmarks and latest systems (13:13-13:22).
    - However, China is "not far behind," with the lead being a "matter of months as opposed to years" (13:24-13:37).
    - He states that the West still has the **algorithmic and innovation edge**, while Chinese companies have been very good at "fast sort of following the current state-of-the-art" but haven't shown new algorithmic innovation (13:45-14:08).